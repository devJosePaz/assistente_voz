# ğŸ™ï¸ Assistente de Voz em Python (STT + LLM + TTS)

Assistente de voz local que realiza Speech-to-Text (STT), processa a entrada
com um modelo de linguagem remoto (LLM) e gera a resposta em Ã¡udio
via Text-to-Speech (TTS).

O foco do projeto Ã©:

- Uso e consumo de APIs de InteligÃªncia Artificial, com atenÃ§Ã£o a custo, latÃªncia e retorno em bytes
- IntegraÃ§Ã£o entre STT, LLM e TTS em um Ãºnico fluxo funcional
- CompreensÃ£o prÃ¡tica de como modelos diferentes se conectam em produÃ§Ã£o

---

## Fluxo de funcionamento

1. Entrada de voz pelo microfone
2. Captura de Ã¡udio em tempo real (sounddevice)
3. PersistÃªncia do Ã¡udio em "audio.wav"
4. TranscriÃ§Ã£o de fala para texto (Whisper)
5. Processamento de linguagem natural (LLM remoto)
6. ConversÃ£o de texto em fala (TTS â€“ ElevenLabs)
7. ReproduÃ§Ã£o local do Ã¡udio gerado ("tts.mp3")

---

## Estrutura do projeto

.
â”œâ”€â”€ main.py # Orquestrador
â”œâ”€â”€ stt.py # GravaÃ§Ã£o de Ã¡udio (sounddevice)
â”œâ”€â”€ transcription.py # Whisper (STT)
â”œâ”€â”€ llm.py # LLM remoto
â”œâ”€â”€ tts.py # Text-to-Speech
â”œâ”€â”€ audio_player.py # ReproduÃ§Ã£o do Ã¡udio
â”œâ”€â”€ client.py # Tokens (.env)
â”œâ”€â”€ audio.wav
â”œâ”€â”€ tts.mp3

---

## Tecnologias

- Python â€” linguagem principal
- sounddevice + scipy â€” captura de Ã¡udio e salvamento em WAV
- Whisper (modelo: small) â€” Speech-to-Text
- Hugging Face Router â€” acesso remoto a LLMs
  - Modelo LLM: openai/gpt-oss-120b:fastest
- ElevenLabs (Text-to-Speech) â€” geraÃ§Ã£o de Ã¡udio em MP3
  - Modelo TTS: eleven_multilingual_v2
- playsound / sounddevice â€” reproduÃ§Ã£o local do Ã¡udio
- python-dotenv â€” gerenciamento de variÃ¡veis de ambiente

---

## ConfiguraÃ§Ã£o

Crie um arquivo ".env":

TOKEN_LLM=seu_token_llm
TOKEN_TTS=seu_token_tts

---

## ExecuÃ§Ã£o

python main.py

ENTER inicia a gravaÃ§Ã£o
ENTER para parar

O sistema transcreve, gera a resposta e fala automaticamente.
